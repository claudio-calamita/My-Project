{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Coursera\n",
    "In this project I want to explore Naples City (Italy) in order to show it is a good City for an investment in hotels and restaurant.\n",
    "The mayor is trying to relaunch the city. He is in charge from **Vedere Anno**. We had several events as **Coppa Devis da Vedere** , **La coppa America** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's first of all try to import data for boroughs and neighborhoods__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests # library to handle requests\n",
    "import html5lib #parser\n",
    "import lxml\n",
    "\n",
    "import pandas as pd ### library for manipulating data as dataframe\n",
    "\n",
    "import functools as ft ## function tools for reduce command\n",
    "\n",
    "import numpy as np ## numpy array\n",
    "\n",
    "import matplotlib ## library for plotting \n",
    "import matplotlib.pyplot as plt ## plots\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colorslib\n",
    "%matplotlib inline\n",
    "\n",
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "import folium # map rendering library\n",
    "import shapefile\n",
    "\n",
    "import seaborn as sns #plotting and statistics\n",
    "\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "from sklearn.cluster import KMeans # library for clustering\n",
    "\n",
    "from io import StringIO\n",
    "from folium import plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataframe for boroughs and neighborhoods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape site\n",
    "res_all = requests.get(\"https://it.wikipedia.org/wiki/Municipalit%C3%A0_di_Napoli\")\n",
    "soup_all = BeautifulSoup(res_all.content, features='html')\n",
    "\n",
    "# convert in dataframe\n",
    "table = soup_all.find_all('table')[0] \n",
    "df = pd.read_html(str(table))[0]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import geospatial data for every borough\n",
    "In the website scraped are not present the coordinates for every borough but you can find in the site for the specific borough. The site are always of same form, changing just the number of borough. In every site the coordinates are in 'span class = \"geo\"'. \n",
    "\n",
    "__In order To build the data frame let's do the following steps:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. take the base site type: \"https://it.wikipedia.org/wiki/Municipalit%C3%A0_\" + number + \"_di_Napoli\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstPartOfSite = \"https://it.wikipedia.org/wiki/Municipalit%C3%A0_\"\n",
    "thirdPartOfSite = \"_di_Napoli\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. take the number of boroughs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberBoroughs = len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. do for cycle for every borough building url and scraping site:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = [];\n",
    "longitude = [];\n",
    "for number in range(1, numberBoroughs+1): ### the right extreme of range is not inclusive\n",
    "    ## Define url\n",
    "    url = firstPartOfSite + str(number) + thirdPartOfSite\n",
    "    \n",
    "    ## Scrape site\n",
    "    res_borough = requests.get(url)\n",
    "    soup_borough = BeautifulSoup(res_borough.content, features='html')\n",
    "    \n",
    "    ## Get Coordinates\n",
    "    coordinates = soup_borough.find_all('span', attrs={\"class\":\"geo\"})[0].text\n",
    "    latLong = [float(coord) for coord in (coordinates.split('; '))]\n",
    "    latitude.append(latLong[0])\n",
    "    longitude.append(latLong[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Presidente', 'Mappa'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename\n",
    "df.columns = ['Municipality', 'Surface_km2', 'Population', 'Density_per_km2', 'Neighborhood']\n",
    "\n",
    "## Modify Municipality\n",
    "df['Municipality'] = df['Municipality'].str.replace(\" \", \"_\")\n",
    "\n",
    "## Modify Surface\n",
    "surface_numpy = df['Surface_km2'].to_numpy()\n",
    "df['Surface_km2'] = [float(num.split()[0].replace(\",\",\".\")) for num in surface_numpy]\n",
    "\n",
    "## Modify Population\n",
    "population_numpy = df['Population'].to_numpy()\n",
    "df['Population'] = [float(ft.reduce(lambda x, y: x + y, num.split())) for num in population_numpy]\n",
    "\n",
    "## Modify Density\n",
    "df['Density_per_km2'] = np.around(np.divide(df['Population'].to_numpy(), df['Surface_km2'].to_numpy()), decimals = 2)\n",
    "\n",
    "## Add numbers of Neighborhoods for descritive analyses\n",
    "neighborhood_numpy = df['Neighborhood'].to_numpy()\n",
    "number_Neighborhoods = [neigh.split(',') for neigh in neighborhood_numpy]\n",
    "number_Neighborhoods = [len(a) for a in number_Neighborhoods]\n",
    "df['number_Neighborhoods'] = number_Neighborhoods\n",
    " \n",
    "## Add Latitude and Longitude\n",
    "df['Latitude'] = latitude\n",
    "df['Longitude'] = longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Boroughs on map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize a map\n",
    "### Use geopy to extract a coordinate for Naples address \n",
    "address = 'Napoli, Na'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"my_explorer\", timeout=10)\n",
    "\n",
    "location = geolocator.geocode(address)\n",
    "latAddress = location.latitude\n",
    "longAddress = location.longitude\n",
    "\n",
    "print('The geograpical coordinate of Naples are {}, {}.'.format(latAddress, longAddress))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create map of Naples using latitude and longitude values\n",
    "map_naples = folium.Map(location=[latAddress, longAddress], zoom_start=10)\n",
    "\n",
    "# add markers to map\n",
    "for lat, lng, borough, neighborhood in zip(df['Latitude'], df['Longitude'], df['Municipality'], df['Neighborhood']):\n",
    "    label = '{}, {}'.format(neighborhood, borough)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.5,\n",
    "        parse_html=False).add_to(map_naples)  \n",
    "    \n",
    "map_naples    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's import shapefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisi descrittiva del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bar Plot\n",
    "x = np.arange(1, len(df)+1)  # the label locations\n",
    "\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, axs = plt.subplots(2,2) ## Create a figure and a set of sublots\n",
    "fig.set_size_inches(15, 8)\n",
    "colors = ['black', 'red', 'green', 'blue']\n",
    "\n",
    "# Plot Surface\n",
    "axs[0,0].bar(x, df['Surface_km2'].to_numpy(), width, label='Surface_km2', color = colors[0])\n",
    "\n",
    "axs[0,0].set_xlabel('Municipality')\n",
    "axs[0,0].set_xticks(x)\n",
    "axs[0,0].set_ylabel('km^2')\n",
    "axs[0,0].legend()\n",
    "\n",
    "# Plot Population\n",
    "axs[0,1].bar(x, df['Population'].to_numpy(), width, label='Population', color = colors[1])\n",
    "\n",
    "axs[0,1].set_xlabel('Municipality')\n",
    "axs[0,1].set_xticks(x)\n",
    "axs[0,1].legend()\n",
    "\n",
    "# Plot Density\n",
    "axs[1,0].bar(x, df['Density_per_km2'].to_numpy(), width, label='Density_per_km2', color = colors[2])\n",
    "\n",
    "axs[1,0].set_xlabel('Municipality')\n",
    "axs[1,0].set_xticks(x)\n",
    "axs[1,0].set_ylabel('1/km^2')\n",
    "axs[1,0].legend()\n",
    "\n",
    "# Plot Number Neighborhood\n",
    "axs[1,1].bar(x, df['number_Neighborhoods'].to_numpy(), width, label='number_Neighborhoods', color = colors[3])\n",
    "axs[1,1].set_xlabel('Municipality')\n",
    "axs[1,1].set_xticks(x)\n",
    "axs[1,1].legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can note that population is concentrated primarly in municipality with lower surface. So in this area there is a greater density of population and a greater number of neighborhoods (*second municipality shows 6 neighborhoods and ~20000 people per squared kilometer*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Let's see some scatter to better highlight these features_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['Surface_km2'], df['Population'])\n",
    "plt.xlabel('Surface km^2')\n",
    "plt.ylabel('Population')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a net separation at 12 squared kilometers. Let's count the overall population at this cut value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLower = df[df['Surface_km2']<12]\n",
    "populationLower = dfLower['Population'].sum()\n",
    "\n",
    "dfUpper = df[df['Surface_km2']>12]\n",
    "populationUpper = dfUpper['Population'].sum()\n",
    "\n",
    "print(\"Population with in municipality with Surface lower than 12 squared kilometers: %d\" % populationLower)\n",
    "print(\"Population with in municipality with Surface greater than 12 squared kilometers: %d\" % populationUpper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['number_Neighborhoods'], df['Population'])\n",
    "plt.xlabel('number_Neighborhoods')\n",
    "plt.ylabel('Population')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The population is primarly concentrated in municipality with low number of Neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['number_Neighborhoods'], df['Surface_km2'])\n",
    "plt.xlabel('number_Neighborhoods')\n",
    "plt.ylabel('Surface_km2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Si prova ad estrarre i dati relativi alla temperatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Define url\n",
    "url = \"https://en.climate-data.org/europe/italy/campania/naples-4561/\"\n",
    "    \n",
    "## Scrape site\n",
    "res_temperature = requests.get(url)\n",
    "soup_temperature = BeautifulSoup(res_temperature.content, features='html5')\n",
    "\n",
    "## extract wiki table\n",
    "table_temp = soup_temperature.find_all('table', attrs={\"id\":\"weather_table\"}) ## la table è unica\n",
    "\n",
    "df_temp = pd.read_html(str(table_temp))[0]\n",
    "df_temp = df_temp.transpose()\n",
    "df_temp = df_temp.reset_index()\n",
    "df_temp.drop(0, inplace = True)\n",
    "df_temp = df_temp.reset_index(drop=True)\n",
    "df_temp.columns = [\"Month\",\"AvgTemp_C\", \"MinTemp_C\", \"MaxTemp_C\", \"AvgTemp_F\", \"MinTemp_F\", \"MaxTemp_F\", \"Rainfall_mm\"]## rename columns\n",
    "df_temp[[\"AvgTemp_C\", \"MinTemp_C\", \"MaxTemp_C\", \"AvgTemp_F\", \"MinTemp_F\", \"MaxTemp_F\", \"Rainfall_mm\"]] = df_temp[[\"AvgTemp_C\", \"MinTemp_C\", \"MaxTemp_C\", \"AvgTemp_F\", \"MinTemp_F\", \"MaxTemp_F\", \"Rainfall_mm\"]].astype(float) ## convert numerical values to float\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "#LinePlot\n",
    "ax1.plot(df_temp[\"Month\"],df_temp[\"AvgTemp_C\"], 'red', linewidth=2.0)\n",
    "ax1.fill_between(df_temp[\"Month\"], df_temp[\"MinTemp_C\"], df_temp[\"MaxTemp_C\"], alpha=0.2, color=\"red\")\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.set_ylabel(\"T(°C)\")\n",
    "\n",
    "#BarPlot\n",
    "ax2.bar(df_temp[\"Month\"], df_temp[\"Rainfall_mm\"], 0.35, label='Rainfall (mm)', color=\"red\")\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.legend(loc='upper right', fontsize = 18)\n",
    "ax2.set_ylabel(\"Rainfall (mm)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Giusto per fare anche un confronto con New York per avere una idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define url\n",
    "url_nk = \"https://en.climate-data.org/north-america/united-states-of-america/new-york/new-york-1091/\"\n",
    "    \n",
    "## Scrape site\n",
    "res_temperature_nk = requests.get(url_nk)\n",
    "soup_temperature_nk = BeautifulSoup(res_temperature_nk.content, features='html5')\n",
    "\n",
    "## extract wiki table\n",
    "table_temp_nk = soup_temperature_nk.find_all('table', attrs={\"id\":\"weather_table\"}) ## la table è unica\n",
    "\n",
    "df_temp_nk = pd.read_html(str(table_temp_nk))[0]\n",
    "df_temp_nk = df_temp_nk.transpose()\n",
    "df_temp_nk = df_temp_nk.reset_index()\n",
    "df_temp_nk.drop(0, inplace = True)\n",
    "df_temp_nk.columns = [\"Month\",\"AvgTemp_C\", \"MinTemp_C\", \"MaxTemp_C\", \"AvgTemp_F\", \"MinTemp_F\", \"MaxTemp_F\", \"Rainfall_mm\"]## rename columns\n",
    "df_temp_nk[[\"AvgTemp_C\", \"MinTemp_C\", \"MaxTemp_C\", \"AvgTemp_F\", \"MinTemp_F\", \"MaxTemp_F\", \"Rainfall_mm\"]] = df_temp_nk[[\"AvgTemp_C\", \"MinTemp_C\", \"MaxTemp_C\", \"AvgTemp_F\", \"MinTemp_F\", \"MaxTemp_F\", \"Rainfall_mm\"]].astype(float) ## convert numerical values to float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax3, ax4) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "x = np.arange(1, 13)  # the label locations\n",
    "\n",
    "#LinePlot\n",
    "ax3.plot(df_temp_nk[\"Month\"],df_temp_nk[\"AvgTemp_C\"], 'blue', linewidth=2.0)\n",
    "ax3.fill_between(df_temp_nk[\"Month\"], df_temp_nk[\"MinTemp_C\"], df_temp_nk[\"MaxTemp_C\"], alpha=0.4, color=\"blue\")\n",
    "\n",
    "ax3.plot(df_temp[\"Month\"], df_temp[\"AvgTemp_C\"], 'red', linewidth=2.0)\n",
    "ax3.fill_between(df_temp[\"Month\"], df_temp[\"MinTemp_C\"], df_temp[\"MaxTemp_C\"], alpha=0.2, color=\"red\")\n",
    "\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "ax3.set_ylabel(\"T(°C)\")\n",
    "ax3.legend([\"New York\", \"Naples\"], fontsize = 15)\n",
    "\n",
    "#BarPlot\n",
    "width = 0.35\n",
    "ax4.bar(x - width/2, df_temp[\"Rainfall_mm\"], 0.35, label='Rainfall Naples (mm)', color=\"red\")\n",
    "ax4.bar(x + width/2, df_temp_nk[\"Rainfall_mm\"], 0.35, label='Rainfall New York (mm)', color=\"blue\")\n",
    "\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "\n",
    "ax4.legend(loc='upper right', fontsize = 15)\n",
    "ax4.set_ylabel(\"Rainfall (mm)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nella prossima sezione si vedrà l'applicazione di Foursquare API per estrarre i locali presenti in ogni sezione "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "CLIENT_ID = 'SJVYFAOYIMC1JV4K5TXAO5C5DR2GEJPYNVQ00JEJEFRNIF1L' #  Foursquare ID\n",
    "CLIENT_SECRET = 'SKTMQ0K2AKDPS5FFWFC5K4VUZZXSEKTR12D555T2LB1NORXT' #  Foursquare Secret\n",
    "VERSION = '20180605' # Foursquare API version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's explore the first Neighborhood in the dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_latitude = df.loc[0, 'Latitude'] # neighborhood latitude value\n",
    "neighborhood_longitude = df.loc[0, 'Longitude'] # neighborhood longitude value\n",
    "\n",
    "neighborhood_name = df.loc[0, 'Neighborhood'] # neighborhood name\n",
    "\n",
    "print('Latitude and longitude values of {} are {}, {}.'.format(neighborhood_name, \n",
    "                                                               neighborhood_latitude, \n",
    "                                                               neighborhood_longitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, let's get the top 100 venues that are in The Beaches within a radius of 500 meters.\n",
    "\n",
    "## First, let's create the GET request URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT = 1000000 # limit of number of venues returned by Foursquare API\n",
    "radius = 1000 # define radius\n",
    "\n",
    "# create URL\n",
    "url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "    CLIENT_ID, \n",
    "    CLIENT_SECRET, \n",
    "    VERSION, \n",
    "    neighborhood_latitude, \n",
    "    neighborhood_longitude, \n",
    "    radius, \n",
    "    LIMIT)\n",
    "\n",
    "## Do request\n",
    "results = requests.get(url).json()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interesting information is contained in the items category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that extracts the category of the venue\n",
    "def get_category_type(row):\n",
    "    try:\n",
    "        categories_list = row['categories']\n",
    "    except:\n",
    "        categories_list = row['venue.categories']\n",
    "        \n",
    "    if len(categories_list) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return categories_list[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "venues = results['response']['groups'][0]['items']\n",
    "    \n",
    "nearby_venues = json_normalize(venues) # flatten JSON\n",
    "\n",
    "# filter columns\n",
    "filtered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\n",
    "nearby_venues =nearby_venues.loc[:, filtered_columns]\n",
    "\n",
    "# filter the category for each row\n",
    "nearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n",
    "\n",
    "# clean columns\n",
    "nearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n",
    "\n",
    "nearby_venues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Neighborhoods in Naples\n",
    "\n",
    "#### Let's create a function to repeat the same process of the previous section to all the neighborhoods in Naples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearbyVenues(names, latitudes, longitudes, radius=1500, LIMIT = 150):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Neighborhood', \n",
    "                  'Neighborhood Latitude', \n",
    "                  'Neighborhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now run the above function on each neighborhood and create a new dataframe called *naples_venues*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naples_venues = getNearbyVenues(names=df['Neighborhood'],\n",
    "                                   latitudes=df['Latitude'],\n",
    "                                   longitudes=df['Longitude']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naples_venues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many venues were returned for each neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naples_venues.groupby('Neighborhood').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Analyze Each Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "naples_onehot = pd.get_dummies(naples_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add neighborhood column back to dataframe\n",
    "naples_onehot['Neighborhood'] = naples_venues['Neighborhood'] \n",
    "\n",
    "# move neighborhood column to the first column\n",
    "fixed_columns = [naples_onehot.columns[-1]] + list(naples_onehot.columns[:-1])\n",
    "naples_onehot = naples_onehot[fixed_columns]\n",
    "\n",
    "naples_onehot.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, let's group rows by neighborhood and by taking the mean of the frequency of occurrence of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naples_grouped = naples_onehot.groupby('Neighborhood').mean().reset_index()\n",
    "naples_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's print each neighborhood along with the top 5 most common venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 5\n",
    "\n",
    "for hood in naples_grouped['Neighborhood']:\n",
    "    print(\"----\"+hood+\"----\")\n",
    "    temp = naples_grouped[naples_grouped['Neighborhood'] == hood].T.reset_index()\n",
    "    temp.columns = ['venue','freq']\n",
    "    temp = temp.iloc[1:]\n",
    "    temp['freq'] = temp['freq'].astype(float)\n",
    "    temp = temp.round({'freq': 2})\n",
    "    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's put that into a *pandas* dataframe\n",
    "\n",
    "First, let's write a function to sort the venues in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the new dataframe and display the top 10 venues for each neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 10\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['Neighborhood']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "neighborhoods_venues_sorted = pd.DataFrame(columns=columns)\n",
    "neighborhoods_venues_sorted['Neighborhood'] = naples_grouped['Neighborhood']\n",
    "\n",
    "for ind in np.arange(naples_grouped.shape[0]):\n",
    "    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(naples_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "neighborhoods_venues_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Neighborhoods\n",
    "\n",
    "## After superimposed Data on map let's define the number of cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate besk K\n",
    "Sum_of_squared_distances = []\n",
    "K = range(1,9)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(naples_grouped_clustering)\n",
    "    Sum_of_squared_distances.append(km.inertia_)\n",
    "\n",
    "## Plot k and range\n",
    "plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum of squared distances')\n",
    "plt.title('Elbow Method For Optimal k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The optimal cut is for k = 5\n",
    "kclusters = 5\n",
    "\n",
    "naples_grouped_clustering = naples_grouped.drop('Neighborhood', 1)\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(naples_grouped_clustering)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_[0:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new dataframe that includes the cluster as well as the top 10 venues for each neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add clustering labels\n",
    "neighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n",
    "\n",
    "naples_merged = df\n",
    "\n",
    "# merge naples_grouped with naples_data to add latitude/longitude for each neighborhood\n",
    "naples_merged = naples_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n",
    "\n",
    "naples_merged.head() # check the last columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods_venues_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting clusters on Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create map\n",
    "map_clusters = folium.Map(location=[latAddress, longAddress], zoom_start=11)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colorslib.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(naples_merged['Latitude'], naples_merged['Longitude'], naples_merged['Neighborhood'], naples_merged['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=10,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=1).add_to(map_clusters)\n",
    "       \n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Una prossima idea potrebbe ssere quella di analizzare ogni cluster, capire quelli più interessanti per certe caratteristiche. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naples_merged.loc[naples_merged['Cluster Labels'] == 0, naples_merged.columns[[1] + list(range(5, naples_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster 1 is characterized by a place primarily for Reastaurant, fast food, cafe, ice cream shop. It is near the sea, and has a very great appeal for turism  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naples_merged.loc[naples_merged['Cluster Labels'] == 1, naples_merged.columns[[1] + list(range(5, naples_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naples_merged.loc[naples_merged['Cluster Labels'] == 2, naples_merged.columns[[1] + list(range(5, naples_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "naples_merged.loc[naples_merged['Cluster Labels'] == 3, naples_merged.columns[[1] + list(range(5, naples_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naples_merged.loc[naples_merged['Cluster Labels'] == 4, naples_merged.columns[[1] + list(range(5, naples_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vediamo di convergere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape site\n",
    "res_employ = requests.get(\"https://en.wikipedia.org/wiki/Naples\")\n",
    "soup_employ = BeautifulSoup(res_employ.content, features='html')\n",
    "\n",
    "# convert in dataframe\n",
    "table_employ = soup_employ.find_all('table', attrs={'class':'wikitable'})[4]\n",
    "df_employ = pd.read_html(str(table_employ), flavor='bs4')[0]\n",
    "df_employ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risultati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Si potrebbe fare una density area per ogni attività, hotel, ristorante, pizza place\n",
    "I cluster 1 e 5 sono quelli più periferici della città e sono rated principalmente per station or bakery\n",
    "Il cluster 3 è più residenziale, con palestra, yoga, cafe, station, supermarket\n",
    "cluster 2 è più rated per ristoranti, \n",
    "cluster 4 per hotel e pizza place ed è la zona del centro storico e di musei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatMapForCategory(search_query, LIMIT = 100000000, radius = 10000):\n",
    "    url_category = 'https://api.foursquare.com/v2/venues/search?client_id={}&client_secret={}&ll={},{}&v={}&query={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET, latAddress, longAddress, VERSION, search_query, radius, LIMIT)\n",
    "    results = requests.get(url_category).json()\n",
    "    heatMap = map_clusters \n",
    "    \n",
    "    # assign relevant part of JSON to venues\n",
    "    venues = results['response']['venues']\n",
    "    \n",
    "    # tranform venues into a dataframe\n",
    "    category_json = json_normalize(venues)\n",
    "    category = category_json[['name', 'location.lat', 'location.lng']]\n",
    "\n",
    "    # convert to (n, 2) nd-array format for heatmap\n",
    "    stationArr = category[['location.lat', 'location.lng']].as_matrix()\n",
    "\n",
    "    heatMap.add_children(plugins.HeatMap(stationArr, radius=20))\n",
    "    return heatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Quello che voglio mostrare è che zone per aprire un hotel sono quelle del cluster 4, così anche il pizza place, mi aspetto una mappa più hot in queste zone\n",
    "# Proviamo a fare una query su Fousquare per Hotel\n",
    "#search_query = \"hotel\"\n",
    "#heatMap_New_hotel = heatMapForCategory(search_query)\n",
    "\n",
    "# Ora voglio mostrare un altro cluster per le pizzerie sempre in questa zona\n",
    "#search_query = \"pizza\"\n",
    "#heatMap_New_pizza = heatMapForCategory(search_query)\n",
    "\n",
    "# Vediamo per le pizzerie\n",
    "search_query = \"restaurant\"\n",
    "heatMap_New_restaurant = heatMapForCategory(search_query)\n",
    "\n",
    "######COME FARE UN CLONE DELLA MAPPA???????????????????######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatMap_New_restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I confini sono stati scaricati dall'openData del comune di Napoli in formato shapefile. Gli shapefile contengono geometrie nello standard Well Known Text che descrive gli elementi di una mappa come Point, LineString, Polygon e collection omogenee di questi oggetti. Poiché nei dati del comune le geometrie erano poligonali, con il software opensource QGIS si è estratto da esse i boundary come LineString e si è creato un nuovo shapefile caricato su github. Si è imposto come sistema di riferimento il 4326, comunemente utilizzato per descrivere le coordinate nei sistemi GNSS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundariesLong = []\n",
    "oundariesLat = []\n",
    "with shapefile.Reader(\"/Users/claudiocalamita/Desktop/confini.shp\") as sf: ## sarà da fare un import su github\n",
    "    ### Get Geometries \n",
    "    shapes = sf.shapes()\n",
    "    ## For every line\n",
    "    boundariesLong = [p[0] for p in geometry.points for geometry in shapes] \n",
    "    boundariesLat  = [p[1] for p in geometry.points for geometry in shapes] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# add markers to map\n",
    "for lat, lng in zip(boundariesLong, boundariesLat):\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=2,\n",
    "        popup=\"\",\n",
    "        color='red',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.5,\n",
    "        parse_html=False).add_to(map_clusters)  \n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit3851e706179449cf8666eb08db445c37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
